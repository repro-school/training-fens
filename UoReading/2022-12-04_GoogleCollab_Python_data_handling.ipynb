{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/repro-school/training-fens/blob/main/Python_data_handling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tRh13PD8ne1"
      },
      "source": [
        "# Neuroimaging in python: Nilearn, Nibabel and Nipype."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cV2FO8c8ne4"
      },
      "source": [
        "## Goals\n",
        "\n",
        "1. Demonstrate data input and output with nibabel.\n",
        "2. Demonstrate interacting with nifi headers.\n",
        "3. Demonstrate manipulating image volumes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2ZM6fym8ne4"
      },
      "source": [
        "Nibabel and Nilearn are two very useful packages for neuroimaging data manipulation. \n",
        "\n",
        "[Nibabel](https://nipy.org/nibabel/) is a package designed for interacting with neuroimaging data in common formats.\n",
        "\n",
        "[Nilearn](https://nilearn.github.io/) is a much broader package that has the functionality to perform machine learning. There are examples of all the wonderful things you can do [here](https://nilearn.github.io/auto_examples/index.html). However, I will not be covering machine learning here. I will only be talking about some of the useful functions that nilearn has for plotting/manipulating data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwH-r3Kz8ne5"
      },
      "source": [
        "## Data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_0qNLq78ne5"
      },
      "source": [
        "First, let's download our data. This includes some functional data, an atlas a brain mask and a few other things."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install nibabel\n",
        "! pip install nilearn\n",
        "\n",
        "!pip install --upgrade --no-cache-dir gdown\n",
        "\n",
        "import gdown\n",
        "\n",
        "url = 'https://drive.google.com/drive/folders/1_l-SQNRzZkaBhp5d2PJd8eu0MHueYL15?usp=sharing&confirm=t'\n",
        "output = '/content/example_data'\n",
        "gdown.download_folder(url=url, output=output, quiet=False)"
      ],
      "metadata": {
        "id": "06-6i1568obZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interactive viewers.\n",
        "\n",
        "Nilearn comes with the capacity to interactively view images. To test that this functionality is working, lets plot the first volume of our functional data."
      ],
      "metadata": {
        "id": "RY6NT65gYxhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "funcpath='/content/example_data/filtered_func_data.nii.gz'"
      ],
      "metadata": {
        "id": "zcEhoUif-1wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pn7zM8he8ne8"
      },
      "outputs": [],
      "source": [
        "import nilearn\n",
        "from nilearn import image\n",
        "from nilearn import plotting\n",
        "import matplotlib.pyplot as plt\n",
        "firstim=image.index_img(funcpath, 0)\n",
        "plotting.view_img(firstim,bg_img=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvXT4gf58ne9"
      },
      "source": [
        "## How do I get nifti data into python?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzC5811O8ne9"
      },
      "source": [
        "To do this, we need to import nibabel, and call the 'load' function to load our data into memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sHn2Dm18ne-"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gi5_8qLc8ne-"
      },
      "outputs": [],
      "source": [
        "img1=nib.load(funcpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Na06r5298ne-"
      },
      "outputs": [],
      "source": [
        "img1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUOxBMrb8ne-"
      },
      "source": [
        "We see that this is a nifti image. Nibabel actually seperates this file into 3 components, *the data*, *the header*, and *the affine*.\n",
        "\n",
        "Let's start with the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN556tpy8ne_"
      },
      "source": [
        "To access the data itself, we call the *get_data* function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDQjAdO18ne_"
      },
      "outputs": [],
      "source": [
        "data=img1.get_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHsuqhYY8ne_"
      },
      "source": [
        "## How do I access different parts of the data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erQqIlud8ne_"
      },
      "source": [
        "It is first important to learn something about the structure of the data. To do this, we can ask how many dimensions it has."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVFrpwHK8nfA"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpK6PmIf8nfA"
      },
      "outputs": [],
      "source": [
        "type(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MVnprhp8nfA"
      },
      "source": [
        "We see that the data has 4 dimensions. It is a functional image. The first 3 are space dimensions (X,Y,Z) and the final one is time. \n",
        "\n",
        "Thus our data are 64x64x21 voxels with 122 volumes.\n",
        "\n",
        "Our data are in a *numpy* array. This is just the standard format in which arrays are stored in python. It is not much different to how data are stored in multidimensional arrays in matlab or R.\n",
        "\n",
        "Therefore, we can access the first volume of our data as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibaoQHSZ8nfA"
      },
      "outputs": [],
      "source": [
        "firstvol=data[:,:,:,0]\n",
        "firstvol.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iceEqnoS8nfA"
      },
      "source": [
        "Here, the colons denote that we want 'all of' the x,y and z dimensions, but the 0 indicates that we only want the first volume. Note that, in python, indexing starts at 0.\n",
        "\n",
        "Therefore, if we ask for the 122nd volume, as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzfUimv68nfA"
      },
      "outputs": [],
      "source": [
        "#lastvol=data[:,:,:,122]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofomHTAw8nfB"
      },
      "source": [
        "We will get an error. Since our indexing starts at 0, the 122nd volume is at index 121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUZSWyLy8nfB"
      },
      "outputs": [],
      "source": [
        "lastvol=data[:,:,:,121]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lastvol=data[:,:,:,-1]"
      ],
      "metadata": {
        "id": "5b1qzv-is5lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU8As9cA8nfB"
      },
      "source": [
        "This can be a little confusing, since the way python does indexing is different to R, MATLAB etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmK3j3XR8nfB"
      },
      "source": [
        "Now let's suppose that we wanted to access one slice of the data in the x dimension, we would do this as follows.\n",
        "\n",
        "Here for instance, we take slice 40 in the X dimension, from the first volume. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jn85eT_98nfB"
      },
      "outputs": [],
      "source": [
        "myslice=data[40,:,:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtG0RHuI8nfB"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVrz9Mtg8nfB"
      },
      "source": [
        "Since a slice is 2 dimensional, we can view it as as we would any other image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iu-12bkz8nfC"
      },
      "outputs": [],
      "source": [
        "plt.imshow(myslice)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEljIoYH8nfC"
      },
      "source": [
        "Often, we may be quite interested in plotting data over time.\n",
        "\n",
        "Let's say for instance, we wanted to plot data from an individual voxel over the course of the run.\n",
        "\n",
        "Here, we would populate the first 3 dimensions with an index to indicate the voxel we want, but add a colon in the time dimension to indicate we want the whole timeseries. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etoQ5Wpg8nfC"
      },
      "outputs": [],
      "source": [
        "ts=data[22,12,14,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xjo9-bAs8nfC"
      },
      "outputs": [],
      "source": [
        "plt.plot(ts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_wdWaOJ8nfC"
      },
      "source": [
        "## How do I perform arithmetic on volumes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xPJBrI38nfC"
      },
      "source": [
        "Often, we may want to perform some arithmetic on functional volumes. For instance, sometimes it is useful to make a mean functional image.\n",
        "\n",
        "Since our data are in numpy format, we can use numpy functions to manipulate them. Therefore, we can simply ask for the mean, specifying that we want to average over the time dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eJMtkXw8nfC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "meanvol=np.mean(data,axis=3) # Time is the 3rd dimension\n",
        "meanvol.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuVesIOd8nfD"
      },
      "source": [
        "## How can I save nifti files?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV8cjrst8nfD"
      },
      "source": [
        "Nibabel also allows you to save nifit files. For instance, we can save our mean functional volume to a nifti image as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFZ-46vT8nfD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "outpath='/content/example_data/outputs'\n",
        "os.mkdir(outpath)\n",
        "\n",
        "\n",
        "new_img = nib.Nifti1Image(meanvol,affine=img1.affine,header=img1.header)\n",
        "fname=os.path.join(outpath,'meanvol.nii.gz')\n",
        "nib.save(new_img,fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt4LZ3do8nfD"
      },
      "source": [
        "Notice that, in order to save to a nifti file, we also need to specify 'header' and 'affine' information (More on this in a moment).\n",
        "\n",
        "Now we plot our mean functional image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4FYOmXq8nfD"
      },
      "outputs": [],
      "source": [
        "display=plotting.plot_anat(fname)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ei4ES8_88nfE"
      },
      "source": [
        "In addition to caculating a mean over time, we may also want to calculate a mean across 2 functional runs. To do this, we would do as follows.\n",
        "\n",
        "Note that we only have 1 set of data and so here we are just averaging across two of the same run (ordinarily, of course, we would average across two different runs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9IdHwFH8nfE"
      },
      "outputs": [],
      "source": [
        "runs = [None]*2 # Make an empty list \n",
        "runs[0]=data # Data from the first run\n",
        "runs[1]=data # Data from the second run\n",
        "runs=np.array(runs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVGCAKUu8nfE"
      },
      "outputs": [],
      "source": [
        "runs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oJT4Uhq8nfE"
      },
      "source": [
        "Now we have a new numpy array, with the run number as a new first axis. Therefore, we just have to average across this new axis to average the data across runs. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-Woz2gO8nfE"
      },
      "outputs": [],
      "source": [
        "run_average=np.mean(runs,axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DW118ceT8nfE"
      },
      "outputs": [],
      "source": [
        "run_average.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU8NA_928nfE"
      },
      "source": [
        "## How do I interact with the information stored in the nifti header?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1b5oooX8nfE"
      },
      "source": [
        "In order to access the nifti header, we do as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDyMdGUn8nfF"
      },
      "outputs": [],
      "source": [
        "print(img1.header)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9PnfrWT8nfF"
      },
      "source": [
        "Here we see a whole bunch of fields. Here I define a function for getting the most important stuff."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J2uLQ8G8nfF"
      },
      "outputs": [],
      "source": [
        "def getniftibits(file):\n",
        "    import pandas as pd\n",
        "    \n",
        "    nifti = nib.load(file)\n",
        "    VOXSIZE = nifti.header['pixdim'][1:4]\n",
        "    SHAPE= (nifti.header['dim'][1:5])\n",
        "    TR = (nifti.header['pixdim'][4:5])\n",
        "    VOXFRAME=pd.DataFrame(VOXSIZE)\n",
        "    VOXFRAME=VOXFRAME.T\n",
        "    SHAPEFRAME=pd.DataFrame(SHAPE)\n",
        "    SHAPEFRAME=SHAPEFRAME.T\n",
        "    VOXFRAME.columns=['VoxsizeX','VoxsizeY','VoxsizeZ']\n",
        "    SHAPEFRAME.columns=['ShapeX','ShapeY','ShapeZ','Volumes']\n",
        "    CFRAMEi=pd.concat([VOXFRAME,SHAPEFRAME],axis=1)\n",
        "    CFRAMEi['TR'] = TR \n",
        "    return(CFRAMEi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUi1S-6h8nfF"
      },
      "outputs": [],
      "source": [
        "v=getniftibits(funcpath)\n",
        "v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG-i7iJW8nfF"
      },
      "source": [
        "We can see that the voxel size (mm), dimensions, repetition time (s) and number of volumes are all stored in here. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2dTyNr_8nfF"
      },
      "source": [
        "The *srow* data describe affine transformations that explain how our voxel data relate to positions relative to the magnet isocentre. You can read more on this [here](https://nipy.org/nibabel/coordinate_systems.html) and [here](https://nilearn.github.io/auto_examples/04_manipulating_images/plot_affine_transformation.html#sphx-glr-auto-examples-04-manipulating-images-plot-affine-transformation-py)\n",
        "\n",
        "This affine information can also be accessed more directly as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TR7LJUk8nfF"
      },
      "outputs": [],
      "source": [
        "img1.affine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey9fq8uD8nfG"
      },
      "source": [
        "## How do I resample images?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaGTGDpb8nfG"
      },
      "source": [
        "Let's suppose that we wanted to resample some data.\n",
        "\n",
        "A possible reason for this is that we have some functional data sampled in MNI 2mm space and we want to know what voxels correspond to regions of interest in an atlas.\n",
        "\n",
        "Unfortunately, our atlas is in MNI 1mm space. Therefore, it may make sense to downsample the atlas into the same space as our data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5-4n_yq8nfG"
      },
      "source": [
        "To do this, we would define our MNI 152 in 2mm space as a template (nilearn actually has its own copy of this)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6oth5tB8nfG"
      },
      "outputs": [],
      "source": [
        "from nilearn.datasets import load_mni152_template\n",
        "template = load_mni152_template()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qn0V_cP_8nfG"
      },
      "outputs": [],
      "source": [
        "template.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIwrpffD8nfG"
      },
      "source": [
        "We would then define our atlas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVHSv5zw8nfG"
      },
      "outputs": [],
      "source": [
        "atlaspath='/content/example_data/maxprob_vol_rh.nii.gz'\n",
        "\n",
        "atlas=nib.load(atlaspath)\n",
        "atlas.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v=getniftibits(atlaspath)\n",
        "v"
      ],
      "metadata": {
        "id": "VSIwaoCpAoO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-N0q5_88nfG"
      },
      "source": [
        "This is in MNI 152 1mm space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJBqdene8nfG"
      },
      "source": [
        "We would then use the nilearn utility 'resample_to_img' to sample our atlas into 2mm space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlMdjomU8nfH"
      },
      "outputs": [],
      "source": [
        "resampled_img = image.resample_to_img(atlas, template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBuVAb5e8nfH"
      },
      "outputs": [],
      "source": [
        "resampled_img.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3lW8Dbc8nfH"
      },
      "source": [
        "Our atlas is now in the space that we want. And we can then save it as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yS4b17ux8nfH"
      },
      "outputs": [],
      "source": [
        "fname=os.path.join(outpath,'atlas_resampled.nii.gz')\n",
        "nib.save(resampled_img,fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzP5rYt98nfH"
      },
      "outputs": [],
      "source": [
        "from nilearn.plotting import plot_roi\n",
        "\n",
        "plot_roi(resampled_img,template, display_mode='z', cut_coords=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Fbjk9WO8nfH"
      },
      "source": [
        "Here, we plot the regions of interest onto the MNI brain."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How do I plot statistical results onto the brain?"
      ],
      "metadata": {
        "id": "vhmgKtXSBVPb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember the motor mapping task we did in FSL? I have imported the t statistics here."
      ],
      "metadata": {
        "id": "UhS3lMPYBdbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stat_data='/content/example_data/tstat1.nii.gz'\n",
        "\n",
        "plotting.plot_stat_map(stat_data,threshold=2,display_mode='x',symmetric_cbar=False,cmap='plasma')"
      ],
      "metadata": {
        "id": "I4a7P-6MBOj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercises\n",
        "\n",
        "## Exercises: A.\n",
        "\n",
        "1. using the functional data defined in 'data', plot the timecourses from the following voxels: [24,17,10], [34,18,11].\n",
        "2. Plot the average of the two timecourses.\n"
      ],
      "metadata": {
        "id": "njIW4DrdXaHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Put your answer here:"
      ],
      "metadata": {
        "id": "gFM4H0LcYKaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ↓ --- Reveal solution\n",
        "\n",
        "ts1=data[24,17,10,:]\n",
        "ts2=data[34,18,11,:]\n",
        "mtc=np.mean([ts1,ts2],axis=0)\n",
        "\n",
        "plt.plot(ts1)\n",
        "plt.plot(ts2)\n",
        "plt.plot(mtc)\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vQRle_QQYL3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercises: B.\n",
        "\n",
        "1. Calcuate the [tsnr](http://www.newbi4fmri.com/mini-tutorial-signal-to-noise#:~:text=For%20each%20voxel%2C%20we%20divide%20the%20mean%20signal%20intensity%20over%20time%20by%20the%20standard%20deviation%20of%20voxel%20time%20course) of the functional volume (that defined in 'data').\n",
        "2. Save this out to a nifti file.\n",
        "3. Use [this function](https://nilearn.github.io/dev/modules/generated/nilearn.plotting.plot_img.html#nilearn.plotting.plot_img) to plot this new TSNR image. Set vmin to 0. Set the display mode to x."
      ],
      "metadata": {
        "id": "iGNl0cuoR0Y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Put your answer here:"
      ],
      "metadata": {
        "id": "xr3Ebh0HWjA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ↓ --- Reveal solution\n",
        "\n",
        "tsnr = np.mean(data,axis=3) / np.std(data,axis=3)\n",
        "\n",
        "new_img = nib.Nifti1Image(tsnr,affine=img1.affine,header=img1.header)\n",
        "fname=os.path.join(outpath,'tsnr.nii.gz')\n",
        "nib.save(new_img,fname)\n",
        "nilearn.plotting.plot_img(fname,bg_img=None,vmin=0,display_mode='x')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SlJvmOzHSn0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercises: C.\n",
        "\n",
        "1. Create a new array: *zscored_data* that zscores data over time ([look here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.zscore.html))\n",
        "2. Plot the same timecourses as in A again."
      ],
      "metadata": {
        "id": "UNWHbtsbZzfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Put your answer here:"
      ],
      "metadata": {
        "id": "N2NLJrZzaQB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ↓ --- Reveal solution\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "zscored_data=stats.zscore(data,axis=3)\n",
        "\n",
        "ts1=zscored_data[24,17,10,:]\n",
        "ts2=zscored_data[34,18,11,:]\n",
        "mtc=np.mean([ts1,ts2],axis=0)\n",
        "\n",
        "plt.plot(ts1)\n",
        "plt.plot(ts2)\n",
        "plt.plot(mtc)\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UJF_Mw3Wahl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercises: D.\n",
        "\n",
        "1. In /content/example_data there is a file called 'bold.nii.gz'\n",
        "2. What is the voxel size?\n",
        "3. What was the TR?\n",
        "4. Print the nifti header of this file."
      ],
      "metadata": {
        "id": "iD95sUttbyTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ↓ --- Reveal solution\n",
        "\n",
        "funcpath2='/content/example_data/bold.nii.gz'\n",
        "\n",
        "v=getniftibits(funcpath2)\n",
        "print(v)\n",
        "\n",
        "im2=nib.load(funcpath2)\n",
        "print(im2.header)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Dx6FPOPXcIHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python as a 'glue' for fMRI software: Nipype\n",
        "\n",
        "The simplest way of thinking about nipype is as an interface (or set of interfaces) that allow all of our favourite neuroimaging packages to talk to one another and work effectively together. To get nipype to work on your computer, you should visit their[website](https://nipype.readthedocs.io/en/latest/quickstart.html) and take alook at this great [tutorial](https://miykael.github.io/nipype_tutorial/).\n",
        "\n",
        "Here cannot install the underlying packages we need (FSL/AFNI) etc in the usual way, so we need to rely on something called [neurodesk](https://www.neurodesk.org/) to create an image of the software packages pre-installed on our system."
      ],
      "metadata": {
        "id": "wF9PFYSpSwG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install CVMFS packages for ubuntu/debian:\n",
        "!pip install nipype\n",
        "!apt-get update >> /dev/null\n",
        "!apt-get install lsb-release >> /dev/null\n",
        "!wget https://ecsft.cern.ch/dist/cvmfs/cvmfs-release/cvmfs-release-latest_all.deb >> /dev/null\n",
        "!dpkg -i cvmfs-release-latest_all.deb >> /dev/null\n",
        "!rm -f cvmfs-release-latest_all.deb\n",
        "!apt-get update >> /dev/null\n",
        "!apt-get install cvmfs singularity-container tree >> /dev/null\n",
        "\n",
        "# this just suppresses a few unessary messages\n",
        "import os\n",
        "LD_PRELOAD = os.getenv('LD_PRELOAD')\n",
        "print(LD_PRELOAD)\n",
        "os.environ['LD_PRELOAD'] = ''\n",
        "\n",
        "#this makes the /content directory available to the software containers\n",
        "SINGULARITY_BINDPATH = os.getenv('SINGULARITY_BINDPATH')\n",
        "print(SINGULARITY_BINDPATH)\n",
        "os.environ['SINGULARITY_BINDPATH'] = '/content'\n",
        "\n",
        "\n",
        "#setup cvmfs\n",
        "!mkdir -p /etc/cvmfs/keys/ardc.edu.au/\n",
        "!echo \"-----BEGIN PUBLIC KEY-----\" | sudo tee /etc/cvmfs/keys/ardc.edu.au/neurodesk.ardc.edu.au.pub\n",
        "!echo \"MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAwUPEmxDp217SAtZxaBep\" | sudo tee -a /etc/cvmfs/keys/ardc.edu.au/neurodesk.ardc.edu.au.pub\n",
        "!echo \"Bi2TQcLoh5AJ//HSIz68ypjOGFjwExGlHb95Frhu1SpcH5OASbV+jJ60oEBLi3sD\" | sudo tee -a /etc/cvmfs/keys/ardc.edu.au/neurodesk.ardc.edu.au.pub\n",
        "!echo \"qA6rGYt9kVi90lWvEjQnhBkPb0uWcp1gNqQAUocybCzHvoiG3fUzAe259CrK09qR\" | sudo tee -a /etc/cvmfs/keys/ardc.edu.au/neurodesk.ardc.edu.au.pub\n",
        "!echo \"pX8sZhgK3eHlfx4ycyMiIQeg66AHlgVCJ2fKa6fl1vnh6adJEPULmn6vZnevvUke\" | sudo tee -a /etc/cvmfs/keys/ardc.edu.au/neurodesk.ardc.edu.au.pub\n",
        "!echo \"I6U1VcYTKm5dPMrOlY/fGimKlyWvivzVv1laa5TAR2Dt4CfdQncOz+rkXmWjLjkD\" | sudo tee -a /etc/cvmfs/keys/ardc.edu.au/neurodesk.ardc.edu.au.pub\n",
        "!echo \"87WMiTgtKybsmMLb2yCGSgLSArlSWhbMA0MaZSzAwE9PJKCCMvTANo5644zc8jBe\" | sudo tee -a /etc/cvmfs/keys/ardc.edu.au/neurodesk.ardc.edu.au.pub\n",
        "!echo \"NQIDAQAB\" | sudo tee -a /etc/cvmfs/keys/ardc.edu.au/neurodesk.ardc.edu.au.pub\n",
        "!echo \"-----END PUBLIC KEY-----\" | sudo tee -a /etc/cvmfs/keys/ardc.edu.au/neurodesk.ardc.edu.au.pub\n",
        "\n",
        "!echo \"CVMFS_USE_GEOAPI=yes\" | sudo tee /etc/cvmfs/config.d/neurodesk.ardc.edu.au.conf\n",
        "!echo 'CVMFS_SERVER_URL=\"http://cvmfs.neurodesk.org/cvmfs/@fqrn@\"' | sudo tee -a /etc/cvmfs/config.d/neurodesk.ardc.edu.au.conf\n",
        "!echo 'CVMFS_KEYS_DIR=\"/etc/cvmfs/keys/ardc.edu.au/\"' | sudo tee -a /etc/cvmfs/config.d/neurodesk.ardc.edu.au.conf\n",
        "\n",
        "!echo \"CVMFS_HTTP_PROXY=DIRECT\" | sudo tee  /etc/cvmfs/default.local\n",
        "!echo \"CVMFS_QUOTA_LIMIT=5000\" | sudo tee -a  /etc/cvmfs/default.local\n",
        "\n",
        "!cvmfs_config setup\n",
        "!cvmfs_config chksetup\n",
        "!cvmfs_config probe neurodesk.ardc.edu.au\n",
        "!ls /cvmfs/neurodesk.ardc.edu.au/\n",
        "!cvmfs_config stat -v neurodesk.ardc.edu.au\n",
        "!cvmfs_talk -i neurodesk.ardc.edu.au host probe\n",
        "!cvmfs_talk -i neurodesk.ardc.edu.au host info\n"
      ],
      "metadata": {
        "id": "NmAUprClIBkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can access all our container images in the neurodesk project (https://neurodesk.github.io/applications/). This includes FSL/ AFNI etc"
      ],
      "metadata": {
        "id": "2zEKXXppILS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /cvmfs/neurodesk.ardc.edu.au/containers"
      ],
      "metadata": {
        "id": "xki3vNeTIKVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we can access any tool we need by talking to this image. Here, FSL:"
      ],
      "metadata": {
        "id": "PkVqOE4PIVd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!singularity exec /cvmfs/neurodesk.ardc.edu.au/containers/fsl_6.0.5.1_20220120/fsl_6.0.5.1_20220120.simg bet"
      ],
      "metadata": {
        "id": "Ds7oKeBFISvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, AFNI:"
      ],
      "metadata": {
        "id": "_7xrhbmWbByi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!singularity exec /cvmfs/neurodesk.ardc.edu.au/containers/afni_21.2.00_20210714/afni_21.2.00_20210714.simg 3dBlurInMask"
      ],
      "metadata": {
        "id": "gao9ER5aIYBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Minimal example: Slice-timing correction in FSL\n",
        "\n",
        "Let's suppose that we wanted to perform a fairly common task, like slice-timing in FSL. How would we do this in nipype?\n",
        "\n",
        "As a first step, we would refer to the relevant nipype documentation, which gives us a brief example of how to do this, and lists a set of inputs and outputs.\n",
        "\n",
        "https://nipype.readthedocs.io/en/0.12.1/interfaces/generated/nipype.interfaces.fsl.preprocess.html#slicetimer\n",
        "\n",
        "This reference should be considered your **bible** that you consult for guidance about how to run virtually any process within the nipype framework. There are sub-sections for interfaces for [AFNI](https://nipype.readthedocs.io/en/0.12.1/interfaces/generated/nipype.interfaces.afni.preprocess.html),[ANTS](https://nipype.readthedocs.io/en/0.12.1/interfaces/generated/nipype.interfaces.ants.registration.html) [SPM](https://nipype.readthedocs.io/en/0.12.1/interfaces/generated/nipype.interfaces.spm.preprocess.html)  etc....\n",
        "\n",
        "We won't copy their example verbatim, and we will include our own example data."
      ],
      "metadata": {
        "id": "JZm-Iov9U1HY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First we import the necessary modules. This includes the fsl interface.\n",
        "from nipype.interfaces import fsl\n",
        "from nipype.testing import example_data\n",
        "\n",
        "# Next, we indicate the  specific function we are using from that interface.\n",
        "\n",
        "st = fsl.SliceTimer()\n",
        "\n",
        "# We then define inputs to this function, including the directory of the \n",
        "\n",
        "st.inputs.in_file='/content/example_data/filtered_func_data.nii.gz'\n",
        "st.inputs.out_file='filtered_func_data_st.nii.gz'\n",
        "\n",
        "st.inputs.interleaved = True\n",
        "st.inputs.time_repetition=int(3)"
      ],
      "metadata": {
        "id": "9ZbzIcfbJKoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st._cmd"
      ],
      "metadata": {
        "id": "NgeODp14Vct-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because FSL is installed in a slightly diferent way, we need to modify the name of the command. "
      ],
      "metadata": {
        "id": "IZxiDzHbVQ_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "st._cmd='singularity exec /cvmfs/neurodesk.ardc.edu.au/containers/fsl_6.0.5.1_20220120/fsl_6.0.5.1_20220120.simg slicetimer'"
      ],
      "metadata": {
        "id": "zou0UvrVJzj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essentially, what nipype does is take these options, translate them and pass them to the command line. We can query what information is being sent to the command line as follows:"
      ],
      "metadata": {
        "id": "i5HQz6kGVLrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "st.cmdline"
      ],
      "metadata": {
        "id": "yn8JfcPoKjgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then run this as follows, which will create out slice-timing corrected file at */content/filtered_func_data_st.nii.gz*"
      ],
      "metadata": {
        "id": "VDUHc7IBV1zC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "st.run()"
      ],
      "metadata": {
        "id": "nauLLi3PKDE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A Minimal example: A Simple Workflow.\n",
        "\n",
        "The real power of nipype isn't simply calling external functions from within python.\n",
        "\n",
        "Instead, nipype provides a simple method for connecting these functions together, into something called a **workflow**.\n",
        "\n",
        "Lets say, for instance, that I want to\n",
        "\n",
        "1. Perform slice-timing correction with FSL\n",
        "2. I want to  smooth the data using AFNI.\n",
        "3. I want to  detrend the data using AFNI\n",
        "\n",
        "This would be a bit of a pain ordinarily, as we would need to switch between these programs. In nipype this is simplified - as we simply need to define a *workflow* that connects all these functions together.\n",
        "\n",
        "Below I give an annotated example of this. \n",
        "\n"
      ],
      "metadata": {
        "id": "tHb28rOSWYuD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. We define nodes and the inputs to these nodes.\n",
        "\n",
        "Nodes are essentially self-contained functions, such as the slice timing operation we just performed.\n",
        "\n",
        "Here I add a set of nodes for performing the various tasks I mentioned above. I have annotated as best as I can below."
      ],
      "metadata": {
        "id": "MzROM_TDW7Dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the relevant interfaces we are using.\n",
        "from nipype.interfaces import afni as afni\n",
        "from nipype.interfaces import fsl as fsl\n",
        "import nipype.interfaces.utility as util \n",
        "import nipype.pipeline.engine as pe\n",
        "\n",
        "\n",
        "# Node 1, slicetiming correction using FSL\n",
        "st=pe.Node(interface=fsl.SliceTimer(),name='slicetime')\n",
        "\n",
        "# Define the inputs\n",
        "st.inputs.in_file = '/content/example_data/filtered_func_data.nii.gz'\n",
        "st.inputs.interleaved = True\n",
        "st.inputs.time_repetition=3\n",
        "st.interface._cmd='singularity exec /cvmfs/neurodesk.ardc.edu.au/containers/fsl_6.0.5.1_20220120/fsl_6.0.5.1_20220120.simg slicetimer'\n",
        "st.inputs.out_file= 'func_st.nii.gz'\n",
        "\n",
        "# Node 2, simultaneous smoothing and brain extraction using AFNI\n",
        "bim=pe.Node(interface=afni.BlurInMask(),name='smooth')\n",
        "# Define the inputs\n",
        "bim.inputs.mask = '/content/example_data/mask.nii.gz' # I give the path to the brain mask.\n",
        "bim.inputs.fwhm = 3.0 # I want 3mm smoothing. \n",
        "bim.inputs.outputtype= 'NIFTI_GZ'\n",
        "bim.interface._cmd='singularity exec /cvmfs/neurodesk.ardc.edu.au/containers/afni_21.2.00_20210714/afni_21.2.00_20210714.simg 3dBlurInMask'\n",
        "bim.inputs.out_file='func_st_blur.nii.gz'\n",
        "\n",
        "# Node 3, detrending using AFNI.\n",
        "dt = pe.Node(interface=afni.Detrend(),name='detrend')                     \n",
        "dt.inputs.args = '-polort 3' # I want to remove polynomials up to an order of 3. \n",
        "dt.inputs.outputtype= 'NIFTI_GZ'\n",
        "dt.interface._cmd='singularity exec /cvmfs/neurodesk.ardc.edu.au/containers/afni_21.2.00_20210714/afni_21.2.00_20210714.simg 3dDetrend'\n",
        "dt.inputs.out_file='func_st_blur_dt.nii.gz'\n"
      ],
      "metadata": {
        "id": "lHtnPOXEMTdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Now we name our workflow and define a directory where the outputs will be stored."
      ],
      "metadata": {
        "id": "Z8dKUrSwXGAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "workflow = pe.Workflow(name='MYWORKFLOW')\n",
        "workflow.base_dir = 'MYWORKFLOW'\n",
        "workflow.base_dir"
      ],
      "metadata": {
        "id": "yRl6UwrtOQhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Now we connect our nodes together"
      ],
      "metadata": {
        "id": "3d3YCMLEXKcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We connect the output of the slicetiming node and make this the input to the smoothing node.\n",
        "workflow.connect(st, 'slice_time_corrected_file', bim, 'in_file')\n",
        "\n",
        "# We connect the output of the smoothing node, and connnect this to the detrend node.\n",
        "workflow.connect(bim, 'out_file', dt, 'in_file')"
      ],
      "metadata": {
        "id": "va8gyTDXOZ84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems quite hard to understand exactly what is happening here. Fortunately, nipype allows us to view everything as a graph. We can write the graph with the following commands."
      ],
      "metadata": {
        "id": "ZtxlVVNUXQxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "workflow.write_graph(graph2use='exec')"
      ],
      "metadata": {
        "id": "nrQtVUEeOpQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the graph. "
      ],
      "metadata": {
        "id": "qzqfsc8yXXgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "import os\n",
        "\n",
        "Image(filename=os.path.join(workflow.base_dir,workflow.name,'graph_detailed.png'))"
      ],
      "metadata": {
        "id": "dulvCiMvPM1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, to recap:\n",
        "\n",
        "1. We first perform slicetiming with fsl,\n",
        "2. We then smooth with AFNI, using the 3Dblurinmask command.\n",
        "3. We then detrend the data.\n",
        "\n",
        "Now we have checked our workflow, all that is left is to.."
      ],
      "metadata": {
        "id": "Oyv5MSZ6Xe28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Run the workflow.\n",
        "\n",
        "We will recieve progress messages as the workflow executes. It is worth reading these, just so you have some idea of what is going on under the hood."
      ],
      "metadata": {
        "id": "1-u4iMz8XscL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result=workflow.run()"
      ],
      "metadata": {
        "id": "NT-YmjMaPOon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a look at the outputs that are stored in /content/MYWORKFLOW. See if you can understand them."
      ],
      "metadata": {
        "id": "JuR3zLE5XvQg"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.15"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}